{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense, Conv2D\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import backend as K\n",
    "print (tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "#load and prepare data. We are using MNIST data and we will pre-process it first\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple encoder network\n",
    "original_dim = 28 * 28\n",
    "intermediate_dim = 64\n",
    "latent_dim = 2\n",
    "\n",
    "inputs = keras.Input(shape=(original_dim,))\n",
    "h = layers.Dense(intermediate_dim, activation='relu')(inputs)\n",
    "z_mean = layers.Dense(latent_dim)(h)\n",
    "z_log_sigma = layers.Dense(latent_dim)(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample new similar points from the latent space\n",
    "def sampling(args):\n",
    "    z_mean, z_log_sigma = args\n",
    "    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim),\n",
    "                              mean=0., stddev=0.1)\n",
    "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
    "\n",
    "z = layers.Lambda(sampling)([z_mean, z_log_sigma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the latent space points to the reconstructed\n",
    "# Create encoder\n",
    "encoder = keras.Model(inputs, [z_mean, z_log_sigma, z], name='encoder')\n",
    "\n",
    "# Create decoder\n",
    "latent_inputs = keras.Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = layers.Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "outputs = layers.Dense(original_dim, activation='sigmoid')(x)\n",
    "decoder = keras.Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = keras.Model(inputs, outputs, name='vae_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "reconstruction_loss = keras.losses.binary_crossentropy(inputs, outputs)\n",
    "reconstruction_loss *= original_dim\n",
    "kl_loss = 1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 188.0416 - val_loss: 167.2570\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 164.8862 - val_loss: 163.0601\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 161.8939 - val_loss: 161.0603\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 159.8943 - val_loss: 159.3362\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 158.2919 - val_loss: 157.9060\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 157.0417 - val_loss: 156.9501\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 156.0370 - val_loss: 155.9004\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 155.2181 - val_loss: 155.3601\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 154.5484 - val_loss: 154.7074\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 153.9249 - val_loss: 154.1578\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 153.4034 - val_loss: 153.6466\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 152.8960 - val_loss: 153.3229\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 152.4391 - val_loss: 152.8493\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 152.0374 - val_loss: 152.4982\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 151.6333 - val_loss: 152.1479\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 151.2135 - val_loss: 151.8172\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 150.7913 - val_loss: 151.6557\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 150.4110 - val_loss: 151.2275\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 150.0791 - val_loss: 150.5574\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 149.7562 - val_loss: 150.5651\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb9fc7c8be0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the VAE model\n",
    "vae.fit(x_train, epochs=20, batch_size=32,validation_data=(x_test, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate new digit\n",
    "n = 2\n",
    "digit_size = 28\n",
    "figure = np.zeros((digit_size * n, digit_size * n))\n",
    "grid_x = np.linspace(-4, 4, n)\n",
    "grid_y = np.linspace(-4, 4, n-1)\n",
    "\n",
    "for i, yi in enumerate(grid_y):\n",
    "    for j, xi in enumerate(grid_x):\n",
    "        z_sample = np.array([[xi/2, yi]])\n",
    "        x_decoded = decoder.predict(z_sample)\n",
    "        digit = x_decoded[0].reshape(digit_size, digit_size)\n",
    "        figure[i * digit_size: (i + 1) * digit_size,\n",
    "               j * digit_size: (j + 1) * digit_size] = digit\n",
    "        plt.imshow(digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
